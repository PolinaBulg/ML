{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceecb1c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.function.trace_type' has no attribute 'Serializable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:45\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDTypeMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(_dtypes\u001b[38;5;241m.\u001b[39mDType), abc\u001b[38;5;241m.\u001b[39mABCMeta):\n\u001b[0;32m     38\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes.DType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDType\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m     _dtypes\u001b[38;5;241m.\u001b[39mDType,\n\u001b[0;32m     44\u001b[0m     trace\u001b[38;5;241m.\u001b[39mTraceType,\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializable\u001b[49m,\n\u001b[0;32m     46\u001b[0m     metaclass\u001b[38;5;241m=\u001b[39mDTypeMeta):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Represents the type of the elements in a `Tensor`.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  `DType`'s are used to specify the output data type for operations which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m  See `tf.dtypes` for a complete list of `DType`'s defined.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m ()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.core.function.trace_type' has no attribute 'Serializable'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfdce97b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.function.trace_type' has no attribute 'Serializable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mC:\\ML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:45\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDTypeMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(_dtypes\u001b[38;5;241m.\u001b[39mDType), abc\u001b[38;5;241m.\u001b[39mABCMeta):\n\u001b[0;32m     38\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes.DType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDType\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m     _dtypes\u001b[38;5;241m.\u001b[39mDType,\n\u001b[0;32m     44\u001b[0m     trace\u001b[38;5;241m.\u001b[39mTraceType,\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializable\u001b[49m,\n\u001b[0;32m     46\u001b[0m     metaclass\u001b[38;5;241m=\u001b[39mDTypeMeta):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Represents the type of the elements in a `Tensor`.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  `DType`'s are used to specify the output data type for operations which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m  See `tf.dtypes` for a complete list of `DType`'s defined.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m ()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.core.function.trace_type' has no attribute 'Serializable'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d691af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/energy_task_new2.csv')\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "y = data['Appliances']\n",
    "X = data.drop(['Appliances'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80923e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('../data/neo_task_new2.csv')\n",
    "data2.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "num_0 = len(data2[data2['hazardous']==0])\n",
    "num_1 = len(data2[data2['hazardous']==1])\n",
    "undersampled_data2 = pd.concat([ data2[data2['hazardous']==0].sample(num_1) , data2[data2['hazardous']==1] ])\n",
    "y_2 = undersampled_data2['hazardous']\n",
    "X_2 = undersampled_data2.drop(['hazardous'], axis=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y_2, stratify=y_2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8792a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>est_diameter_min</th>\n",
       "      <th>est_diameter_max</th>\n",
       "      <th>relative_velocity</th>\n",
       "      <th>miss_distance</th>\n",
       "      <th>absolute_magnitude</th>\n",
       "      <th>hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3561024.0</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>56014.078517</td>\n",
       "      <td>1.024333e+06</td>\n",
       "      <td>26.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54016766.0</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.068240</td>\n",
       "      <td>7864.348060</td>\n",
       "      <td>3.268186e+07</td>\n",
       "      <td>24.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3746620.0</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>55257.544508</td>\n",
       "      <td>6.538636e+07</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3633054.0</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.043057</td>\n",
       "      <td>41531.404722</td>\n",
       "      <td>1.260796e+07</td>\n",
       "      <td>25.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3742124.0</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.311918</td>\n",
       "      <td>67639.394481</td>\n",
       "      <td>7.130590e+07</td>\n",
       "      <td>21.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90831</th>\n",
       "      <td>54231436.0</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>23264.740825</td>\n",
       "      <td>1.635007e+06</td>\n",
       "      <td>25.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90832</th>\n",
       "      <td>3824972.0</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>0.247765</td>\n",
       "      <td>24802.519406</td>\n",
       "      <td>3.351901e+07</td>\n",
       "      <td>21.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90833</th>\n",
       "      <td>3740101.0</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.078350</td>\n",
       "      <td>116288.999548</td>\n",
       "      <td>5.471396e+07</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90834</th>\n",
       "      <td>3691093.0</td>\n",
       "      <td>0.044112</td>\n",
       "      <td>0.098637</td>\n",
       "      <td>45763.317060</td>\n",
       "      <td>2.694877e+07</td>\n",
       "      <td>23.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90835</th>\n",
       "      <td>3600600.0</td>\n",
       "      <td>0.084441</td>\n",
       "      <td>0.188817</td>\n",
       "      <td>79519.526381</td>\n",
       "      <td>3.631207e+07</td>\n",
       "      <td>22.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90836 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  est_diameter_min  est_diameter_max  relative_velocity  \\\n",
       "0       3561024.0          0.016016          0.035813       56014.078517   \n",
       "1      54016766.0          0.030518          0.068240        7864.348060   \n",
       "2       3746620.0          0.055533          0.124177       55257.544508   \n",
       "3       3633054.0          0.019256          0.043057       41531.404722   \n",
       "4       3742124.0          0.139494          0.311918       67639.394481   \n",
       "...           ...               ...               ...                ...   \n",
       "90831  54231436.0          0.017561          0.039268       23264.740825   \n",
       "90832   3824972.0          0.110804          0.247765       24802.519406   \n",
       "90833   3740101.0          0.035039          0.078350      116288.999548   \n",
       "90834   3691093.0          0.044112          0.098637       45763.317060   \n",
       "90835   3600600.0          0.084441          0.188817       79519.526381   \n",
       "\n",
       "       miss_distance  absolute_magnitude  hazardous  \n",
       "0       1.024333e+06               26.10          0  \n",
       "1       3.268186e+07               24.70          0  \n",
       "2       6.538636e+07               23.40          0  \n",
       "3       1.260796e+07               25.70          0  \n",
       "4       7.130590e+07               21.40          0  \n",
       "...              ...                 ...        ...  \n",
       "90831   1.635007e+06               25.90          0  \n",
       "90832   3.351901e+07               21.90          0  \n",
       "90833   5.471396e+07               24.40          0  \n",
       "90834   2.694877e+07               23.90          0  \n",
       "90835   3.631207e+07               22.49          0  \n",
       "\n",
       "[90836 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('../data/neo_task_new2.csv')\n",
    "data2.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3904317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81996 8840\n",
      "17680\n"
     ]
    }
   ],
   "source": [
    "num_0 = len(data2[data2['hazardous']==0])\n",
    "num_1 = len(data2[data2['hazardous']==1])\n",
    "print(num_0,num_1)\n",
    "#  \n",
    "undersampled_data = pd.concat([ data2[data2['hazardous']==0].sample(num_1) , data2[data2['hazardous']==1] ])\n",
    "print(len(undersampled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7b5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classification = undersampled_data['hazardous']\n",
    "X_classification = undersampled_data.drop(['hazardous'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb5c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
    "                                                                                                                y_classification,\n",
    "                                                                                                                stratify=y_classification,\n",
    "                                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8083b680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37158928, -0.33416365, -0.33292289, -1.14898987, -0.83094134,\n",
       "         0.08000733],\n",
       "       [-0.46832142,  0.18399592,  0.18722351, -0.28519735,  1.53823009,\n",
       "        -0.73901522],\n",
       "       [-0.46000565,  0.3096296 ,  0.31333893,  2.05709329,  0.39219818,\n",
       "        -0.85247289],\n",
       "       ...,\n",
       "       [-0.39728186, -0.5125681 , -0.51201143, -0.27132041, -1.55990643,\n",
       "         0.89548432],\n",
       "       [-0.46168841,  0.01836893,  0.02096144, -0.62048966, -0.76418024,\n",
       "        -0.55819206],\n",
       "       [-0.43259997,  0.56309376,  0.56777497,  1.48908409,  1.63774795,\n",
       "        -1.04038715]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_classification_train)\n",
    "X_classification_train = scaler.transform(X_classification_train)\n",
    "X_classification_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ace405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48357308,  0.8935207 ,  0.89946892, -0.39686383, -0.52017692,\n",
       "        -1.23184696],\n",
       "       [-0.46609854, -0.08448275, -0.08228461,  1.98519845,  0.22483414,\n",
       "        -0.41991552],\n",
       "       [-0.46022925, -0.24724857, -0.24567454, -1.17698304,  0.10387276,\n",
       "         0.51492355],\n",
       "       ...,\n",
       "       [-0.42520451, -0.45718286, -0.45641381, -1.40958284, -1.47187765,\n",
       "         0.54092911],\n",
       "       [-0.39194225, -0.58347524, -0.58319045, -1.03941003, -1.71128198,\n",
       "         1.95914997],\n",
       "       [-0.38419458, -0.34645506, -0.34526143,  0.79088115,  1.64797129,\n",
       "         0.11546285]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_classification_test = scaler.transform(X_classification_test)\n",
    "X_classification_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c19238",
   "metadata": {},
   "source": [
    "## TensorFlow Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff800af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15788, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a5bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(30,)),\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428bc311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,609\n",
      "Trainable params: 4,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6c2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af410cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "494/494 [==============================] - 3s 3ms/step - loss: 10951.5664\n",
      "Epoch 2/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 10375.4268\n",
      "Epoch 3/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 10245.6445\n",
      "Epoch 4/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 10202.4961\n",
      "Epoch 5/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 10156.9141\n",
      "Epoch 6/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 10101.6250\n",
      "Epoch 7/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 10096.2168\n",
      "Epoch 8/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 10076.5908\n",
      "Epoch 9/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 10070.6855\n",
      "Epoch 10/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 10023.9658\n",
      "Epoch 11/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9928.1318\n",
      "Epoch 12/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9992.1982\n",
      "Epoch 13/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 9985.9580\n",
      "Epoch 14/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9927.9512\n",
      "Epoch 15/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9916.3008\n",
      "Epoch 16/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9911.8037\n",
      "Epoch 17/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9799.3789\n",
      "Epoch 18/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 9816.8076\n",
      "Epoch 19/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9834.1738\n",
      "Epoch 20/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9724.2734\n",
      "Epoch 21/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9755.2061\n",
      "Epoch 22/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9797.8418\n",
      "Epoch 23/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9692.8965\n",
      "Epoch 24/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9696.2559\n",
      "Epoch 25/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9720.3545\n",
      "Epoch 26/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9696.6406\n",
      "Epoch 27/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9638.6270\n",
      "Epoch 28/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9686.6396\n",
      "Epoch 29/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9634.4844\n",
      "Epoch 30/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9636.4990\n",
      "Epoch 31/50\n",
      "494/494 [==============================] - 2s 4ms/step - loss: 9552.7861\n",
      "Epoch 32/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9617.6230\n",
      "Epoch 33/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9779.8066\n",
      "Epoch 34/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9589.5195\n",
      "Epoch 35/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9596.5186\n",
      "Epoch 36/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9587.5918\n",
      "Epoch 37/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9702.3789\n",
      "Epoch 38/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9634.8721\n",
      "Epoch 39/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9580.3799\n",
      "Epoch 40/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9553.1162\n",
      "Epoch 41/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 9629.9854\n",
      "Epoch 42/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 9567.1709\n",
      "Epoch 43/50\n",
      "494/494 [==============================] - 2s 3ms/step - loss: 9546.2725\n",
      "Epoch 44/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9580.0879\n",
      "Epoch 45/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9587.8906\n",
      "Epoch 46/50\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 9551.8926\n",
      "Epoch 47/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9556.7354\n",
      "Epoch 48/50\n",
      "494/494 [==============================] - 2s 5ms/step - loss: 9476.5801\n",
      "Epoch 49/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9463.2344\n",
      "Epoch 50/50\n",
      "494/494 [==============================] - 1s 2ms/step - loss: 9458.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ed0f40250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "146a6b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 3ms/step\n",
      "48.095416940554266\n",
      "124/124 [==============================] - 0s 2ms/step\n",
      "9110.92049545914\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, model_regression.predict(X_test)))\n",
    "print(mean_squared_error(y_test, model_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053b52b",
   "metadata": {},
   "source": [
    "## TensorFlow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6342fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14144, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_classification_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6aff0de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_classification_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      2\u001b[0m     [\n\u001b[0;32m      3\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,)),\n\u001b[0;32m      4\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.05\u001b[39m),\n\u001b[0;32m      6\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      9\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     10\u001b[0m     ]\n\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(6,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "512ee9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb4e91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "442/442 [==============================] - 1s 1ms/step - loss: 0.3519\n",
      "Epoch 2/25\n",
      "442/442 [==============================] - 0s 1ms/step - loss: 0.3182\n",
      "Epoch 3/25\n",
      "442/442 [==============================] - 0s 1ms/step - loss: 0.3131\n",
      "Epoch 4/25\n",
      "442/442 [==============================] - 1s 1ms/step - loss: 0.3089\n",
      "Epoch 5/25\n",
      "442/442 [==============================] - 0s 1ms/step - loss: 0.3050\n",
      "Epoch 6/25\n",
      "442/442 [==============================] - 0s 956us/step - loss: 0.3042\n",
      "Epoch 7/25\n",
      "442/442 [==============================] - 0s 930us/step - loss: 0.3009\n",
      "Epoch 8/25\n",
      "442/442 [==============================] - 0s 933us/step - loss: 0.3001\n",
      "Epoch 9/25\n",
      "442/442 [==============================] - 0s 941us/step - loss: 0.2984\n",
      "Epoch 10/25\n",
      "442/442 [==============================] - 0s 953us/step - loss: 0.2982\n",
      "Epoch 11/25\n",
      "442/442 [==============================] - 0s 939us/step - loss: 0.2984\n",
      "Epoch 12/25\n",
      "442/442 [==============================] - 0s 942us/step - loss: 0.2966\n",
      "Epoch 13/25\n",
      "442/442 [==============================] - 0s 936us/step - loss: 0.2958\n",
      "Epoch 14/25\n",
      "442/442 [==============================] - 0s 936us/step - loss: 0.2966\n",
      "Epoch 15/25\n",
      "442/442 [==============================] - 0s 940us/step - loss: 0.2956\n",
      "Epoch 16/25\n",
      "442/442 [==============================] - 0s 933us/step - loss: 0.2953\n",
      "Epoch 17/25\n",
      "442/442 [==============================] - 0s 991us/step - loss: 0.2953\n",
      "Epoch 18/25\n",
      "442/442 [==============================] - 0s 952us/step - loss: 0.2940\n",
      "Epoch 19/25\n",
      "442/442 [==============================] - 0s 954us/step - loss: 0.2945\n",
      "Epoch 20/25\n",
      "442/442 [==============================] - 0s 974us/step - loss: 0.2950\n",
      "Epoch 21/25\n",
      "442/442 [==============================] - 0s 969us/step - loss: 0.2923\n",
      "Epoch 22/25\n",
      "442/442 [==============================] - 0s 962us/step - loss: 0.2922\n",
      "Epoch 23/25\n",
      "442/442 [==============================] - 0s 976us/step - loss: 0.2930\n",
      "Epoch 24/25\n",
      "442/442 [==============================] - 0s 941us/step - loss: 0.2916\n",
      "Epoch 25/25\n",
      "442/442 [==============================] - 0s 944us/step - loss: 0.2919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f8893e580>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b4a82ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      1768\n",
      "           1       0.81      0.98      0.89      1768\n",
      "\n",
      "    accuracy                           0.88      3536\n",
      "   macro avg       0.89      0.88      0.87      3536\n",
      "weighted avg       0.89      0.88      0.87      3536\n",
      "\n",
      "[[1358  410]\n",
      " [  29 1739]]\n"
     ]
    }
   ],
   "source": [
    "pred_classification = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, pred_classification))\n",
    "print(confusion_matrix(y_classification_test, pred_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "773b32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/TensorFlow Classification2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/TensorFlow Classification2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_classification_1.save('../models/TensorFlow Classification2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aac44da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('../models/TensorFlow Classification2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecdf36b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      1768\n",
      "           1       0.81      0.98      0.89      1768\n",
      "\n",
      "    accuracy                           0.88      3536\n",
      "   macro avg       0.89      0.88      0.87      3536\n",
      "weighted avg       0.89      0.88      0.87      3536\n",
      "\n",
      "[[1358  410]\n",
      " [  29 1739]]\n"
     ]
    }
   ],
   "source": [
    "pred_classification = np.around(model.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, pred_classification))\n",
    "print(confusion_matrix(y_classification_test, pred_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a777b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "underSampler = RandomUnderSampler(random_state=42)\n",
    "X_classification, y_classification = underSampler.fit_resample(X_classification,y_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e28fa027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(6,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19adb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
    "                                                                                                                y_classification,\n",
    "                                                                                                                stratify=y_classification,\n",
    "                                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26167254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f1dc3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 24959.6094\n",
      "Epoch 2/25\n",
      "442/442 [==============================] - 2s 5ms/step - loss: 3611.5322\n",
      "Epoch 3/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 1087.2595\n",
      "Epoch 4/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 529.2101\n",
      "Epoch 5/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 314.8487\n",
      "Epoch 6/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 244.9636\n",
      "Epoch 7/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 103.8953\n",
      "Epoch 8/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 98.8535\n",
      "Epoch 9/25\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 118.5045\n",
      "Epoch 10/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 2.0755\n",
      "Epoch 11/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 1.1615\n",
      "Epoch 12/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.9716\n",
      "Epoch 13/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.8090\n",
      "Epoch 14/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.8106\n",
      "Epoch 15/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.6765\n",
      "Epoch 16/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.6863\n",
      "Epoch 17/25\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8516\n",
      "Epoch 18/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.9225\n",
      "Epoch 19/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.6845\n",
      "Epoch 20/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.6719\n",
      "Epoch 21/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.6731\n",
      "Epoch 22/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.8599\n",
      "Epoch 23/25\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 11.8235\n",
      "Epoch 24/25\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.6963\n",
      "Epoch 25/25\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f878b8610>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2.fit(X_classification_train, y_classification_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27aa7598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66      1768\n",
      "           1       0.03      0.00      0.00      1768\n",
      "\n",
      "    accuracy                           0.49      3536\n",
      "   macro avg       0.26      0.49      0.33      3536\n",
      "weighted avg       0.26      0.49      0.33      3536\n",
      "\n",
      "[[1734   34]\n",
      " [1767    1]]\n"
     ]
    }
   ],
   "source": [
    "pred_classification = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, pred_classification))\n",
    "print(confusion_matrix(y_classification_test, pred_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e04ad",
   "metadata": {},
   "source": [
    "## perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb833b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2.],\n",
       "       [1., 3., 4.],\n",
       "       [1., 5., 6.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.hstack([np.ones((3, 1)), [[1,2],[3,4],[5,6]]])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c5973b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17548\\1816284130.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  fn = lambda x: 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.32      0.45      1768\n",
      "           1       0.57      0.90      0.70      1768\n",
      "\n",
      "    accuracy                           0.61      3536\n",
      "   macro avg       0.67      0.61      0.57      3536\n",
      "weighted avg       0.67      0.61      0.57      3536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17548\\1816284130.py:43: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.dot(delta, self.W)[:, 1:] * da\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 95.52571573346846\n",
      "MSE: 19514.51735495313\n"
     ]
    }
   ],
   "source": [
    "def iterate_batches(inputs, outputs, batchsize):\n",
    "        l = len(inputs)\n",
    "        for ndx in range(0, l, batchsize):\n",
    "            yield inputs[ndx:min(ndx + batchsize, l)], outputs[ndx:min(ndx + batchsize, l)]\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_units, input_size=None, activation=None):\n",
    "        \n",
    "        self.n_units = n_units                                    \n",
    "        self.input_size = input_size                               \n",
    "        self.W = None                                                                                      \n",
    "        self.A = None                              \n",
    "        self.fn, self.df = self.select_activation_fn(activation)\n",
    "\n",
    "    def select_activation_fn(self, activation):\n",
    "        if activation == 'relu':\n",
    "            fn = lambda x: np.maximum(0, x)\n",
    "            df = lambda x: np.where(x < 0, 0.0, 1.0)\n",
    "        elif activation == 'sigmoid':\n",
    "            fn = lambda x: 1 / (1 + np.exp(-x))\n",
    "            df = lambda x: fn(x) * fn(1 - x)\n",
    "        elif activation == 'tanh':\n",
    "            fn = lambda x: (np.exp(x) - np.exp(-1)) / (np.exp(x) + np.exp(-x))\n",
    "            df = lambda x: 1 / np.cos(x) ** 2\n",
    "        elif activation == 'linear':\n",
    "            fn = lambda x: x\n",
    "            df = lambda x: 1.0\n",
    "        return fn, df\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.W = np.random.randn(self.n_units, self.input_size + 1)\n",
    "    \n",
    "    def get_activation_value(self, X):\n",
    "        m_examples = X.shape[0]\n",
    "        X_new = np.hstack([np.ones((m_examples, 1)), X])\n",
    "        Z = np.dot(X_new, self.W.T)\n",
    "        A = self.fn(Z)\n",
    "        self.A = A\n",
    "        return A\n",
    "    \n",
    "    def backprop(self, delta, a):\n",
    "        da = self.df(a)    \n",
    "        return np.dot(delta, self.W)[:, 1:] * da\n",
    "\n",
    "class SequentialModel:\n",
    "    def __init__(self, layers):     \n",
    "        input_size = layers[0].n_units       \n",
    "        layers[0].init_weights()             \n",
    "        for layer in layers[1:]:             \n",
    "            layer.input_size = input_size\n",
    "            input_size = layer.n_units\n",
    "            layer.init_weights()\n",
    "        self.layers = layers\n",
    "        self.lr = None\n",
    "\n",
    "    def forward(self, X):            \n",
    "        out = self.layers[0].get_activation_value(X)\n",
    "        for layer in self.layers[1:]:\n",
    "            out = layer.get_activation_value(out)\n",
    "        return out\n",
    "    \n",
    "    def add_dim(self, x):\n",
    "        return np.hstack([np.ones((x.shape[0], 1)), x])\n",
    "\n",
    "    def backward(self, X, y_pred, y_true):\n",
    "        n_layers = len(self.layers)\n",
    "        delta = y_pred - y_true\n",
    "        a = y_pred\n",
    "        dWs = {}\n",
    "        for i in range(-1, -len(self.layers), -1):\n",
    "            a = self.layers[i - 1].A       \n",
    "            dWs[i] = np.dot(delta.T, self.add_dim(a))\n",
    "            delta = self.layers[i].backprop(delta, a)\n",
    "\n",
    "        dWs[-n_layers] = np.dot(delta.T, self.add_dim(X))\n",
    "\n",
    "        for k, dW in dWs.items():\n",
    "            self.layers[k].W -= self.lr * dW\n",
    "            \n",
    "    def fit(self, X, y, epochs, batchsize=32, lr=0.01):\n",
    "        \n",
    "        self.lr = lr\n",
    "\n",
    "        for i in range(epochs):\n",
    "\n",
    "            for batch in iterate_batches(X, y, batchsize=batchsize):\n",
    "                \n",
    "                X_batch = batch[0]\n",
    "                y_batch = batch[1]\n",
    "                if not isinstance(y_batch, np.ndarray):\n",
    "                    y_batch = y_batch.to_numpy()\n",
    "                y_batch = y_batch.reshape(-1, 1)\n",
    "                y_pred = model.forward(X_batch)\n",
    "                model.backward(X_batch, y_pred, y_batch)\n",
    "                \n",
    "\n",
    "model = SequentialModel([\n",
    "DenseLayer(6, activation='sigmoid', input_size=X_train2.shape[1]),\n",
    "DenseLayer(4, activation='tanh'),\n",
    "DenseLayer(3, activation='relu'),\n",
    "DenseLayer(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.fit(X_train2, y_train2, epochs = 5, batchsize=32)\n",
    "pred = model.forward(X_test2)\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "print(classification_report(y_test2, pred))\n",
    "\n",
    "\n",
    "model = SequentialModel([\n",
    "DenseLayer(6, activation='relu', input_size=X_train.shape[1]),\n",
    "DenseLayer(4, activation='linear'),\n",
    "DenseLayer(3, activation='relu'),\n",
    "DenseLayer(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 25, batchsize=32)\n",
    "pred = model.forward(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, pred)}')\n",
    "print(f'MSE: {mean_squared_error(y_test, pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8974b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
